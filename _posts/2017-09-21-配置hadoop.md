---
layout:    post
title:    "配置hadoop环境"
subtitle:   "生命在于折腾"
data: 2017-09-10 20:07:56 +0800
author:   "Les1ie"
catalog: true
tags:
   - 学习笔记
   - java
   - hadoop
---

 ## 0x00 序

 前两天一同学来找我问爬虫，知道周五上午有个课程要说爬虫，瞬间兴趣来了，于是今天去上了课，发现挺有趣，现在让我们配置Hadoop,简要记录下过程


 ## 0x01  docker
 国际惯例，找别人的docker镜像
 ```
$ docker search hadoop
NAME                             DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED
sequenceiq/hadoop-docker         An easy way to try Hadoop                       479                  [OK]
sequenceiq/hadoop-ubuntu         An easy way to try Hadoop on Ubuntu             42                   [OK]
uhopper/hadoop                   Base Hadoop image with dynamic configurati...   33                   [OK]
harisekhon/hadoop                Apache Hadoop (HDFS + Yarn, tags 2.5 - 2.7)     17                   [OK]
ruo91/hadoop                     Apache hadoop 2.x - Pseudo-Distributed Mode     12                   [OK]
izone/hadoop                     Hadoop 2.8.1 Ecosystem fully distributed, ...   12                   [OK]
 ```

第一个拖下来，只有1G但是下了好久，fs好多层
```
$ docker pull sequenceiq/hadoop-docker
```
运行试一试

```
$ docker run -it --rm sequenceiq/hadoop-docker /bin/bash
```
看了下，`centos 6.6`，可以直接拿来用 :) 




## 0x02 手动配置
不过还是想试试手动来，生命在于折腾

配置hadoop要改很多东西，所以为了不把服务器环境搞坏了，决定在ubuntu 16.04的docker里面配置，

参考[这里](http://www.powerxing.com/install-hadoop/)和[这里](http://blog.csdn.net/mr_kktian/article/details/64440166)做的配置，助教推荐的是后者

首先加用户
```
$ useradd -m hadoop -s /bin/bash
$ passwd hadoop
```
账户密码都一样

然后装软件
```bash
$ apt install vim openssh-server default-jre -y
```

然后配置java环境，这一次不能用`default-jre`了，因为这次还需要`jdk`， 所以
```
$ apt install openjdk-8-jdk
```
然后就需要配置`JAVA_HOME`的环境变量了

额发现了一个很有趣的东西
```
$ root@3e28365cb0b9:/usr/lib/jvm# ls -al
total 16
drwxr-xr-x  3 root root 4096 Sep 15 10:09 .
drwxr-xr-x 28 root root 4096 Sep 15 10:10 ..
-rw-r--r--  1 root root 2600 Jul 28 02:31 .java-1.8.0-openjdk-amd64.jinfo
lrwxrwxrwx  1 root root   24 Feb 25  2016 default-java -> java-1.8.0-openjdk-amd64
lrwxrwxrwx  1 root root   20 Jul 28 02:31 java-1.8.0-openjdk-amd64 -> java-8-openjdk-amd64
drwxr-xr-x  7 root root 4096 Sep 15 12:22 java-8-openjdk-amd64
```
他们这几个东西其实是一个东西，一个指向另一个，最后还是到了`java-8-openjdk-amd64`这个地方

由于很多个文件都指向这个，所以参考教程中的改名我就没有执行，



所以我们这个地方的`$JAVA_HOME`其实是`/usr/lib/jvm/java-8-1.8.0-openjdk-amd64`
```bash
$ root@3e28365cb0b9:/usr/lib/jvm/java-8-openjdk-amd64# ls
ASSEMBLY_EXCEPTION  THIRD_PARTY_README  bin  docs  include  jre  lib  man  src.zip
```
我们完全不用设置`JAVA_HOME`这个变量，只是可能是长久的习惯，`JAVA_HOME`这个变量就直接指代了`jdk`的安装目录，后面加配置的时候可以少写几行重复的代码，所以我这里也按照长期的习惯加一个`JAVA_HOME`

然后改`~/.bashrc`，把如下内容加到最后四行
```bash
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
```
测试一下
```bash
$ root@3e28365cb0b9:~# java -version
openjdk version "1.8.0_131"
OpenJDK Runtime Environment (build 1.8.0_131-8u131-b11-2ubuntu1.16.04.3-b11)
OpenJDK 64-Bit Server VM (build 25.131-b11, mixed mode)
$ root@3e28365cb0b9:~# javac -version
javac 1.8.0_131
```

下载hadoop， 
```
$ wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.6.5/hadoop-2.6.5.tar.gz
$ tar -xzf hadoop-2.6.5.tar.gz
$ mv hadoop-2.6.5 /usr/local/
```
然后....改个名字吧..
```
$ mv hadoop-2.6.5 hadoop
```


然后, 先去试试能不能用吧..
```
$ cd /usr/local/hadoop/bin
$ ./hadoop version
Hadoop 2.6.5
Subversion https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997
Compiled by sjlee on 2016-10-02T23:43Z
Compiled with protoc 2.5.0
From source with checksum f05c9fa095a395faa9db9f7ba5d754
This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.5.jar
```
搞定，

接下来设置下环境变量吧，这样启动很不优雅
```
# for hadoop
export HADOOP_HOME=/usr/local/hadoop
export CLASSPATH=${$HADOOP_HOME/bin/hadoop classpath}:$CLASSPATH
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```
这个东西加到`.bashrc`里面，然后发现....报错
```
$ bash
bash: CLASSPATH=${$HADOOP_HOME/bin/hadoop classpath}:$CLASSPATH: bad substitution

```
于是注释掉第二行，因为我不是很懂他这个写法..
```
# for hadoop
export HADOOP_HOME=/usr/local/hadoop
#export CLASSPATH=${$HADOOP_HOME/bin/hadoop classpath}:$CLASSPATH
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

然后教程里面让修改`/usr/local/hadoop/etc/hadoop/hadoop-env.sh`添加`export JAVA_HOME=/usr/lib/jvm/java`，我看了下`hadoop-env.sh`发现他写了一行`export JAVA_HOME=${JAVA_HOME}`这个应该是在启动hadoop会在环境变量里面取的，hadoop肯定会在启动bash后面才会启动,所以我先不修改，如果后面出问题了我再来改这个

然后修改同一目录下的`core-site.xml`文件，改成了如下内容
```
<configuration>
<!-- Les1ie write here at 2017.9.21-->
<property>
<name>hadoop.tmp.dir</name>
<value>file:/usr/local/hadoop/tmp</value>
<description> Les1ie's config.</description>
</property>
<name>fs.defaultFS</name>
<value>hdfs://0.0.0.0:9000</value>
<poperty>
</configuration>
```
教程里面是监听的`localhost`，因为我这个是在docker里面配置的，所以我设置的监听`0.0.0.0`，不然外面连不进去


然后改`hdfs-site.xml`

添加如下内容
```
<configuration>
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<name>dfs.namenode.name.dir</name>
<value>file:/usr/local/hadoop/tmp/dfs/name</value>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>file:/usr/local/hadoop/tmp/dfs/data</value>
</property>
</configuration>
```
两个配置文件都是手打进去的，这个vim比较原始没配置，所以连缩进都没有，将就看下吧

嗯运行下
```
$ ./bin/hdfs namenode -format
```
好的配置文件报错一大堆，手打果然不靠谱，挨个改好。

改`core-site.xml`，
```
<configuration>
<!-- Les1ie write here at 2017.9.21-->
<property>
<name>hadoop.tmp.dir</name>
<value>file:/usr/local/hadoop/tmp</value>
<description> Les1ie's config.</description>
</property>
<property>
<name>fs.defaultFS</name>
<value>hdfs://0.0.0.0:9000</value>
</property>
</configuration>
```
然后改`hdfs-site.xml`
```
<configuration>
<property>
<name>dfs.replication</name>
<value>1</value>
</property>

<property>
<name>dfs.namenode.name.dir</name>
<value>file:/usr/local/hadoop/tmp/dfs/name</value>
</property>

<property>
<name>dfs.datanode.data.dir</name>
<value>file:/usr/local/hadoop/tmp/dfs/data</value>
</property>

</configuration>
```

再运行一次初始化

emmm又错了，查看信息

![](http://oqyjccf1n.bkt.clouddn.com/20170921-010054.png)

emmmm我猜是我刚刚把报错的环境变量注释了的锅

然后再启动一次
```
$ ./sbin/start-dfs.sh
```
看到一个报错信息
![](http://oqyjccf1n.bkt.clouddn.com/20170921-010318.png)

这个...不是我刚刚改监听地址的地方么..改`localhost`吧

再次启动，还是说ssh登录失败

于是
```
$ apt install openssh-server curl
$ service ssh start
```
还是登录不上， 想起来这个是docker, root没设置密码

设置里密码还是登不上

emmm发现我是root...还没改sshd里面允许root登录，我个zz，

然后改了之后，重启sshd


登上去了，然后忽然发现根本不需要嘛，

反正都是要配置公钥登录的:)

```
$ ssh-keygen
```
一路回车

然后
```
$ ssh-copy-id localhost
```


再试试`ssh localhost`,搞定


然后再次启动，发现报错找不到`JAVA_HOME`，好的把刚刚省略掉没写的以为会从`bash`的`$PATH`里面取的`$JAVA_HOME`写到了`hadoop-env.sh`，再次启动，搞定
![](http://oqyjccf1n.bkt.clouddn.com/20170921-012039.png)

最后是
```
$ jps
3970 NameNode
4502 Jps
4119 DataNode
4316 SecondaryNameNode
```

然后
```
$ curl localhost:50070
```
好的，通的，搞定

可以打包一份docker传到我的docker hub去了..
```
$ docker commit -a "Les1ie iansmtih@qq.com" -m "Les1ie's tutor for hadoop 2.6.5" hadoop hadoop-tutor:latest
```
还是有点大..1G, 没事传上去
```
$ docker push hadoop-tutor:latest
```
emmmm出了点问题，算了吧，就这样

睡觉睡觉

2017年9月21日01:43:02